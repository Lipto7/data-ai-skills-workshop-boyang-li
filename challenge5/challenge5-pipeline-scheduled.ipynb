{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "OuJFLrz8eriW",
      "metadata": {
        "id": "OuJFLrz8eriW"
      },
      "source": [
        "#### Create vertex ai pipeline for scheduled report run\n",
        "\n",
        "* set up pipeline\n",
        "* schedule to run hourly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vxq2nEmTrWtJUevc4fbLFxhp",
      "metadata": {
        "id": "Vxq2nEmTrWtJUevc4fbLFxhp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install kfp google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "nDsHTyX_SS8t",
      "metadata": {
        "id": "nDsHTyX_SS8t"
      },
      "outputs": [],
      "source": [
        "# pipeline.py\n",
        "import os\n",
        "from kfp import dsl\n",
        "from kfp.dsl import component\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "# -------- Component 1: NWS -> BQ load --------\n",
        "@component(\n",
        "    base_image=\"python:3.11\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-bigquery\",\n",
        "        \"pandas\",\n",
        "        \"pyarrow\",\n",
        "        \"db-dtypes\",\n",
        "        \"requests\",\n",
        "    ],\n",
        ")\n",
        "def fetch_forecasts_to_bq(\n",
        "    project_id: str,\n",
        "    dataset: str,\n",
        "    airports_table: str,\n",
        "    alert_table: str,\n",
        "    sleep_s: float = 0.5,\n",
        "):\n",
        "    import time\n",
        "    import requests\n",
        "    import pandas as pd\n",
        "    from datetime import datetime, timezone\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    bq_client = bigquery.Client(project=project_id)\n",
        "\n",
        "    def get_nws_forecast(lat, lon):\n",
        "        headers = {\"User-Agent\": \"AeroAlertsPipeline/1.0\", \"Accept\": \"application/geo+json\"}\n",
        "        try:\n",
        "            r = requests.get(f\"https://api.weather.gov/points/{lat},{lon}\", headers=headers, timeout=15)\n",
        "            r.raise_for_status()\n",
        "            forecast_url = r.json()[\"properties\"][\"forecast\"]\n",
        "\n",
        "            r2 = requests.get(forecast_url, headers=headers, timeout=15)\n",
        "            r2.raise_for_status()\n",
        "            periods = r2.json()[\"properties\"][\"periods\"][:4]\n",
        "            return \"\\n\".join([f\"{p['name']}: {p['detailedForecast']}\" for p in periods])\n",
        "        except Exception as e:\n",
        "            return f\"Forecast unavailable: {str(e)}\"\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "      id, ident, name, municipality, iso_region, iso_country,\n",
        "      iata_code, icao_code, latitude_deg, longitude_deg\n",
        "    FROM `{airports_table}`\n",
        "    WHERE latitude_deg IS NOT NULL AND longitude_deg IS NOT NULL\n",
        "    \"\"\"\n",
        "    airports = bq_client.query(query).to_dataframe()\n",
        "\n",
        "    rows = []\n",
        "    now_ts = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    for _, row in airports.iterrows():\n",
        "        lat = float(row[\"latitude_deg\"])\n",
        "        lon = float(row[\"longitude_deg\"])\n",
        "        forecast = get_nws_forecast(lat, lon)\n",
        "\n",
        "        rows.append({\n",
        "            \"id\": int(row[\"id\"]),\n",
        "            \"ident\": row[\"ident\"],\n",
        "            \"name\": row[\"name\"],\n",
        "            \"municipality\": row[\"municipality\"],\n",
        "            \"iso_region\": row[\"iso_region\"],\n",
        "            \"iso_country\": row[\"iso_country\"],\n",
        "            \"iata_code\": row[\"iata_code\"],\n",
        "            \"icao_code\": row[\"icao_code\"],\n",
        "            \"latitude_deg\": lat,\n",
        "            \"longitude_deg\": lon,\n",
        "            \"forecast_text\": forecast,\n",
        "            \"forecast_retrieved_at\": now_ts,\n",
        "            \"alert_text\": None,\n",
        "            \"alert_level\": None,\n",
        "            \"alert_summary\": None,\n",
        "            \"alert_generated_at\": None,\n",
        "        })\n",
        "        time.sleep(sleep_s)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
        "    )\n",
        "    load_job = bq_client.load_table_from_dataframe(df, alert_table, job_config=job_config)\n",
        "    load_job.result()\n",
        "\n",
        "    print(f\"Loaded {len(df)} rows into {alert_table}\")\n",
        "\n",
        "\n",
        "# -------- Component 2: BQ ML.GENERATE_TEXT -> rewrite table --------\n",
        "@component(\n",
        "    base_image=\"python:3.11\",\n",
        "    packages_to_install=[\"google-cloud-bigquery\"],\n",
        ")\n",
        "def generate_alerts_in_bq(\n",
        "    project_id: str,\n",
        "    alert_table: str,\n",
        "    model_name: str,\n",
        "    temperature: float = 0.2,\n",
        "    max_output_tokens: int = 2000,\n",
        "):\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    bq_client = bigquery.Client(project=project_id)\n",
        "\n",
        "    sql = f\"\"\"\n",
        "    CREATE OR REPLACE TABLE `{alert_table}` AS\n",
        "    WITH gen AS (\n",
        "      SELECT\n",
        "        x.*,\n",
        "        JSON_VALUE(x.ml_generate_text_result, '$.candidates[0].content.parts[0].text') AS _model_text\n",
        "      FROM ML.GENERATE_TEXT(\n",
        "        MODEL `{model_name}`,\n",
        "        (\n",
        "          SELECT\n",
        "            CONCAT(\n",
        "              'You are an aviation operations assistant. ',\n",
        "              'Output STRICT JSON only. Do NOT wrap in ``` fences. ',\n",
        "              'Keys: alert_level (GREEN/YELLOW/RED), alert_summary (2-4 sentences, actionable), key_hazards (array). ',\n",
        "              'Airport name: ', COALESCE(name, ''), '. ',\n",
        "              'Forecast: ', COALESCE(forecast_text, '')\n",
        "            ) AS prompt,\n",
        "            t.*\n",
        "          FROM `{alert_table}` t\n",
        "          WHERE forecast_text IS NOT NULL\n",
        "        ),\n",
        "        STRUCT(CAST({temperature} AS FLOAT64) AS temperature,\n",
        "               CAST({max_output_tokens} AS INT64) AS max_output_tokens)\n",
        "      ) AS x\n",
        "    ),\n",
        "    final AS (\n",
        "      SELECT\n",
        "        * EXCEPT(\n",
        "          prompt, ml_generate_text_result, ml_generate_text_status,\n",
        "          alert_text, alert_level, alert_summary, alert_generated_at\n",
        "        ),\n",
        "        TRIM(\n",
        "          REGEXP_REPLACE(\n",
        "            REGEXP_REPLACE(_model_text, r'(?is)```json', ''),\n",
        "            r'(?is)```', ''\n",
        "          )\n",
        "        ) AS _cleaned_json\n",
        "      FROM gen\n",
        "    )\n",
        "    SELECT\n",
        "      * EXCEPT(_cleaned_json),\n",
        "      _cleaned_json AS alert_text,\n",
        "      JSON_VALUE(_cleaned_json, '$.alert_level') AS alert_level,\n",
        "      JSON_VALUE(_cleaned_json, '$.alert_summary') AS alert_summary,\n",
        "      CURRENT_TIMESTAMP() AS alert_generated_at\n",
        "    FROM final\n",
        "    \"\"\"\n",
        "    bq_client.query(sql).result()\n",
        "    print(\"Rewritten table:\", alert_table)\n",
        "\n",
        "\n",
        "# -------- Pipeline definition --------\n",
        "@dsl.pipeline(name=\"aero-alerts-pipeline\")\n",
        "def aero_alerts_pipeline(\n",
        "    project_id: str,\n",
        "    region: str = \"us-central1\",\n",
        "    dataset: str = \"challenge5\",\n",
        "):\n",
        "    airports_table = f\"{project_id}.{dataset}.airports\"\n",
        "    alert_table = f\"{project_id}.{dataset}.airport_alerts\"\n",
        "    model_name = f\"{project_id}.{dataset}.gemini_model\"\n",
        "\n",
        "    step_a = fetch_forecasts_to_bq(\n",
        "        project_id=project_id,\n",
        "        dataset=dataset,\n",
        "        airports_table=airports_table,\n",
        "        alert_table=alert_table,\n",
        "    )\n",
        "\n",
        "    generate_alerts_in_bq(\n",
        "        project_id=project_id,\n",
        "        alert_table=alert_table,\n",
        "        model_name=model_name,\n",
        "    ).after(step_a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jLqKe2Z0Td-u",
      "metadata": {
        "id": "jLqKe2Z0Td-u"
      },
      "outputs": [],
      "source": [
        "# Job test to run once\n",
        "if __name__ == \"__main__\":\n",
        "    from kfp import compiler\n",
        "\n",
        "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "    REGION = os.environ.get(\"VERTEX_REGION\", \"us-central1\")\n",
        "\n",
        "    pipeline_json = \"aero_alerts_pipeline.json\"\n",
        "    compiler.Compiler().compile(\n",
        "        pipeline_func=aero_alerts_pipeline,\n",
        "        package_path=pipeline_json,\n",
        "    )\n",
        "\n",
        "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "    job = aiplatform.PipelineJob(\n",
        "        display_name=\"aero-alerts-run\",\n",
        "        template_path=pipeline_json,\n",
        "        parameter_values={\"project_id\": PROJECT_ID, \"region\": REGION, \"dataset\": \"challenge5\"},\n",
        "        enable_caching=False,  # turn on later if you want caching\n",
        "    )\n",
        "    job.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "_MFsYJkBWW9F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MFsYJkBWW9F",
        "outputId": "389fe08b-c867-4df3-a1a9-307e4cd29af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created schedule: projects/603410550/locations/us-central1/schedules/5282542042998636544\n"
          ]
        }
      ],
      "source": [
        "import google.auth\n",
        "from google.cloud import aiplatform\n",
        "from kfp import compiler  # kfp>=2\n",
        "\n",
        "# Get creds + project\n",
        "creds, PROJECT_ID = google.auth.default()\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "# Compile\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func=aero_alerts_pipeline,\n",
        "    package_path=\"pipeline.json\",\n",
        ")\n",
        "\n",
        "# Init Vertex\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
        "\n",
        "pipeline_job = aiplatform.PipelineJob(\n",
        "    display_name=\"aero-alerts-scheduled-run\",\n",
        "    template_path=\"pipeline.json\",\n",
        "    pipeline_root=f\"gs://{PROJECT_ID}-vertex-pipelines/aero-alerts\",  # pick your bucket/path\n",
        "    parameter_values={\n",
        "        \"project_id\": PROJECT_ID,\n",
        "        \"dataset\": \"challenge5\",\n",
        "    },\n",
        "    enable_caching=False,\n",
        ")\n",
        "\n",
        "# Hourly schedule\n",
        "# If you want Pacific time: \"CRON_TZ=America/Los_Angeles 0 * * * *\"\n",
        "schedule = pipeline_job.create_schedule(\n",
        "    cron=\"0 * * * *\",  # default timezone is UTC unless TZ/CRON_TZ prefix is used\n",
        "    display_name=\"hourly_airport_alerts\",\n",
        "    max_run_count=24,\n",
        "    # strongly recommended if your pipeline touches BQ / resources:\n",
        "    # service_account=\"your-sa@your-project.iam.gserviceaccount.com\",\n",
        "    # max_concurrent_run_count=1,\n",
        "    # allow_queueing=False,\n",
        ")\n",
        "print(\"Created schedule:\", schedule.resource_name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "student-00-6acfaff1b079 (Jan 16, 2026, 11:29:40â€¯AM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
